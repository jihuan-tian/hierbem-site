<!DOCTYPE html> 
<html> 
<head><title>2 Lagrange multiplier method and its application in PDEs</title> 
<meta charset='UTF-8' /> 
<link href='hierbem-theory.css' rel='stylesheet' type='text/css' /> 
 <script type='text/x-mathjax-config'> MathJax.Hub.Config({ jax: ["input/TeX", "output/SVG"], extensions: ["tex2jax.js", "color.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js", "TeX/noUndefined.js", "TeX/AMScd.js"], tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], skipTags: ["script","noscript","style","textarea","pre","code"], processEscapes: true, processEnvironments: true, preview: "TeX" }, "HTML-CSS": { scale: 1, availableFonts: ["STIX","TeX"], preferredFont: "TeX", webFont: "TeX", imageFont: "TeX", showMathMenu: true }, MMLorHTML: { prefer: { MSIE: "MML", Firefox: "MML", Opera: "HTML", other: "HTML" } } }); </script>  
<script src='https://jihuan-tian.github.io/hierbem-site/js/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML' type='text/javascript'></script> 
</head><body>
   \( % Math symbol commands
\newcommand{\intd}{\,\mathrm{d}}   % Symbol 'd' used in integration, such as 'dx'
\newcommand{\diff}{\mathrm{d}}     % Symbol 'd' used in differentiation
\newcommand{\Diff}{\mathrm{D}}     % Symbol 'D' used in differentiation
\newcommand{\pdiff}{\partial}   % Partial derivative
\newcommand{\DD}[2]{\frac{\diff}{\diff #2}\left( #1 \right)}
\newcommand{\Dd}[2]{\frac{\diff #1}{\diff #2}}
\newcommand{\PD}[2]{\frac{\pdiff}{\pdiff #2}\left( #1 \right)}
\newcommand{\Pd}[2]{\frac{\pdiff #1}{\pdiff #2}}
\newcommand{\rme}{\mathrm{e}}      % Exponential e
\newcommand{\rmi}{\mathrm{i}}      % Imaginary unit i
\newcommand{\rmj}{\mathrm{j}}      % Imaginary unit j
\newcommand{\vect}[1]{\boldsymbol{#1}}       % Vector typeset in bold and italic
\newcommand{\normvect}{\vect{n}} % Normal vector: n
\newcommand{\dform}[1]{\overset{\rightharpoonup}{\boldsymbol{#1}}}       % Vector for differential form
\newcommand{\cochain}[1]{\overset{\rightharpoonup}{#1}}       % Vector for cochain
\newcommand{\Abs}[1]{\big\lvert#1\big\rvert} % Absolute value (single big vertical bar)
\newcommand{\abs}[1]{\lvert#1\rvert} % Absolute value (single vertical bar)
\newcommand{\Norm}[1]{\big\lVert#1\big\rVert} % Norm (double big vertical bar)
\newcommand{\norm}[1]{\lVert#1\rVert} % Norm (double vertical bar)
\newcommand{\ouset}[3]{\overset{#3}{\underset{#2}{#1}}} % over and under set
% Super/subscript for column index of a matrix, which is used in tensor analysis.
\newcommand{\cscript}[1]{\;\; #1}
\newcommand{\suchthat}{\textit{S.T.\;}} % S.T., such that
% Star symbol used as prefix in front of a paragraph with no indent
\newcommand{\prefstar}{\noindent$\ast$ }      
% Big vertical line restricting the function.
% Example: $u(x)\restrict_{\Omega_0}$
\newcommand{\restrict}{\big\vert}

% Math operators which are typeset in Roman font
\DeclareMathOperator{\sgn}{sgn} % Sign function
\DeclareMathOperator{\erf}{erf} % Error function
\DeclareMathOperator{\Bd}{Bd}   % Boundary of a set or domain, used in topology
\DeclareMathOperator{\Int}{Int} % Interior of a set or domain, used in topology
\DeclareMathOperator{\rank}{rank} % Rank of a matrix
\DeclareMathOperator{\divergence}{div} % Divergence
\DeclareMathOperator{\curl}{curl} % Curl
\DeclareMathOperator{\grad}{grad} % Gradient
\DeclareMathOperator{\diag}{diag} % Diagonal
\DeclareMathOperator{\tr}{tr} % Trace
\DeclareMathOperator{\lhs}{LHS} % Left hand side
\DeclareMathOperator{\rhs}{RHS} % Right hand side
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\esssup}{ess\,sup}
\DeclareMathOperator{\essinf}{ess\,inf}
\DeclareMathOperator{\kernel}{ker} % The kernel set of a map
\DeclareMathOperator{\image}{Im}  % The image set of a map
\DeclareMathOperator{\diam}{diam} % Diameter of a domain or a set
\DeclareMathOperator{\dist}{dist} % Distance between two sets
\DeclareMathOperator{\const}{const}
\DeclareMathOperator{\adj}{adj}
 \)
   <!-- l. 146 --><div class='crosslinks'><p class='noindent'>[<a href='#tailhierbem-theorych2.html'>tail</a>] [<a href='hierbem-theorypa2.html#hierbem-theorych2.html'>up</a>] </p></div>
   <h2 class='chapterHead'><span class='titlemark'>Chapter 2</span><br /><a id='x5-90002'></a>Lagrange multiplier method and its application in PDEs</h2>
   <h3 class='sectionHead'><span class='titlemark'>2.1    </span> <a id='x5-100002.1'></a>Lagrange multiplier method understood from differential geometry</h3>
<!-- l. 150 --><p class='noindent'>The method of Lagrange multiplier is used to find the extremal or saddle points of an objective function \(f(x^1, \cdots , x^n)\) with a
set of \(m\) constraints \begin{equation}  \begin{aligned} \varphi _1(x^1,\cdots ,x^n) &amp;= 0 \\ &amp;\vdots \\ \varphi _m(x^1,\cdots ,x^n) &amp;= 0 \end{aligned}.  \end{equation}<a id='x5-10001r1'></a> In this article, we will understand this method from a differential geometry point of
view.
</p><!-- l. 160 --><p class='indent'>   For the objective function \(f(x^1,\cdots ,x^n) = c\) with a specific output value \(c\), we assume the Jacobian matrix \(Jf\) of the function \(f\) with
respect to the coordinate chart \((x)= (x^1,\cdots ,x^n)\) has a full rank. Obviously, \(Jf\) has only one row, which is not a zero vector.
Therefore, \(Jf\) is a surjective map. According to the implicit function theorem <a href='#x5-100021'>1<!-- tex4ht:ref: theo:implicit-func  --></a>, where \(r=1\), \(f(x^1,\cdots ,x^n)=c\) describes a \((n-1)\)-dimensional
submanifold in \(\mathbb {R}^n\).
</p>
   <div class='theorem'><div class='newtheorem'>
<!-- l. 162 --><p class='noindent'><span class='head'>
<span class='p1xb-x-x-109'>Theorem 1 (Implicit function)</span> </span><a id='x5-10003'></a><span class='p1xi-x-x-109'>Let </span>\(A\) <span class='p1xi-x-x-109'>be an open set in </span>\(\mathbb {R}^{n+r}\) <span class='p1xi-x-x-109'>and </span>\(f: A \rightarrow \mathbb {R}^r\) <span class='p1xi-x-x-109'>be </span>\(\mathbb {C}^r\)<span class='p1xi-x-x-109'>, </span>\(f(x) = t \; \forall x \in A\)<span class='p1xi-x-x-109'>, </span>\(t\) <span class='p1xi-x-x-109'>is a constant in </span>\(\mathbb {R}^r\)<span class='p1xi-x-x-109'>. Then if </span>\(\exists x_0 \in A\) <span class='p1xi-x-x-109'>such that </span>\(\rank \left ( \left [ \frac {\partial f}{\partial x} \right ] \bigg \vert _{x=x_0} \right )=r\)<span class='p1xi-x-x-109'>, then </span>\(\exists \)
<span class='p1xi-x-x-109'>neighborhood </span>\(B\) <span class='p1xi-x-x-109'>of </span>\(x_0\) <span class='p1xi-x-x-109'>in </span>\(\mathbb {R}^{n+r}\) <span class='p1xi-x-x-109'>such that </span>\(\forall x \in B\)<span class='p1xi-x-x-109'>, its </span>\(r\) <span class='p1xi-x-x-109'>components can be uniquely represented by a </span>\(\mathbb {C}^r\) <span class='p1xi-x-x-109'>function </span>\(g\) <span class='p1xi-x-x-109'>in terms of the other </span>\(n\)
<span class='p1xi-x-x-109'>components. If </span>\(\forall x_0 \in A\) <span class='p1xi-x-x-109'>satisfies the above condition, </span>\(A\) <span class='p1xi-x-x-109'>is a </span>\(n\)<span class='p1xi-x-x-109'>-dimensional submanifold in </span>\(\mathbb {R}^{n+r}\)<span class='p1xi-x-x-109'>. Its codimension is </span>\(r\)<span class='p1xi-x-x-109'>.</span> <a id='x5-100021'></a>
</p>
   </div>
<!-- l. 165 --><p class='indent'>   </p></div>
<!-- l. 167 --><p class='indent'>   The implicit function theorem is also equivalent to the main submanifold theorem <a href='#x5-100042'>2<!-- tex4ht:ref: theo:main-submanifold  --></a>.
</p>
   <div class='theorem'><div class='newtheorem'>
<!-- l. 169 --><p class='noindent'><span class='head'>
<span class='p1xb-x-x-109'>Theorem 2 (Main submanifold)</span> </span><a id='x5-10005'></a><span class='p1xi-x-x-109'>Let </span>\(F: \mathbb {R}^{n+r} \rightarrow \mathbb {R}^r\) <span class='p1xi-x-x-109'>and </span>\(F^{-1}(y_0) = \{x \in \mathbb {R}^{n+r} \vert F(x) = y_0\}\) <span class='p1xi-x-x-109'>is not empty. If </span>\(\forall x_0 \in F^{-1}(y_0)\) <span class='p1xi-x-x-109'>the Jacobian map </span>\(F_{*}: \mathbb {R}_{x_0}^{n+r} \rightarrow \mathbb {R}_{y_0}^r\) <span class='p1xi-x-x-109'>is surjective, then </span>\(F^{-1}(y_0)\) <span class='p1xi-x-x-109'>is a </span>\(n\)<span class='p1xi-x-x-109'>-dimensional
</span><span class='p1xi-x-x-109'>submanifold of </span>\(\mathbb {R}^{n+r}\)<span class='p1xi-x-x-109'>.</span> <a id='x5-100042'></a>
</p>
   </div>
<!-- l. 172 --><p class='indent'>   </p></div>
<!-- l. 174 --><p class='indent'>   Here \(F^{-1}(y_0)\) is called the level set of \(F\) with respect to \(y_0\). Therefore, the objective function \(f(x^1,\cdots ,x^n)=c\) with a specific output value \(c\)
<span class='p1xb-x-x-109'>implicitly </span>defines the level set of \(f\) with respect to \(c\). Here we write it as \(M_{\mathrm {o}}^{n-1}\), where the subscript \(\mathrm {o}\) represents “objective
function”.
                                                                                               
                                                                                               
</p><!-- l. 176 --><p class='indent'>   Similarly, for the set of \(m\) constraints, we assume the Jacobian matrix \(J\varphi \) with respect to the chart \((x)\)
has a full rank \(m\). And these constraints define an \((n-m)\)-dimensional submanifold, which also <span class='p1xb-x-x-109'>implicitly</span>
defines the level set of \(\varphi =\left \{ \varphi _1,\cdots ,\varphi _m \right \}\) with respect to \(\mathbf {0}\) in \(\mathbb {R}^m\). Here we write it as \(M_{\mathrm {c}}^{n-m}\), where the subscript \(\mathrm {c}\) represents
“constraints”.
</p><!-- l. 178 --><p class='indent'>   For each constraint function \(\varphi _i(x)=0\), it <span class='p1xb-x-x-109'>implicitly </span>defines a \((n-1)\)-dimensional submanifold, which is the level set of \(\varphi _i\) with
respect to 0 in \(\mathbb {R}\). We write it as \(M_{\mathrm {c}_i}^{n-1}\). Therefore, the level set of \(\varphi \) is the intersection of all level sets for \(\left \{ \varphi _i \right \}_{i=1}^m\):
\begin{equation}  M_{\mathrm {c}}^{n-m} = \bigcap _{i=1}^m M_{\mathrm {c}_i}^{n-1}.  \end{equation}<a id='x5-10006r2'></a>
</p><!-- l. 183 --><p class='indent'>   To find the extremal or saddle points of the objective function \(f\) satisfying the constraints \(\varphi \) is equivalent to find
the points at which the level set \(M_{\mathrm {o}}^{n-1}\) of the objective function and the level of set \(M_{\mathrm {c}}^{n-m}\) of the constraints meet tangentially,
i.e. they share a common tangent plane or tangent space. If two submanifolds or level sets share a
common tangent space, they must also have a common normal space, which is the orthogonal
complement of the tangent space. <span class='p1xb-x-x-109'>The Lagrange multiplier method is based on the normal space
</span><span class='p1xb-x-x-109'>formulation.</span>
</p><!-- l. 185 --><p class='indent'>   The normal space can be derived from the differential 1-form of the implicit map used for describing the level
set as below.
</p><!-- l. 187 --><p class='indent'>   For the objective function \(f\), apply the 1-form \(df\) to a tangent vector \(\frac {\mathrm {d} x}{\mathrm {d} t}\), where \(x(t)\) is an arbitrary curve which is
contained in \(M_{\mathrm {o}}^{n-1}\) and passes through a point \(p\) in \(M_{\mathrm {o}}^{n-1}\). Because \(M_{\mathrm {o}}^{n-1}\) is a level set of \(f\) with respect to \(0\), \(f(x(t))\) is \(0\) for all \(t\). Therefore, \begin{equation}  df \left ( \frac {\diff x}{\diff t} \right ) = \sum _{i=1}^n \frac {\diff x^{i}}{\diff t} \frac {\partial f}{\partial x^i} = \frac {\partial f}{\partial t} = 0.  \end{equation}<a id='x5-10007r3'></a> This
is equivalent to \begin{equation}  \left \langle \nabla f, \frac {\diff x}{\diff t} \right \rangle = 0,  \end{equation}<a id='x5-10008r4'></a> i.e. the gradient vector \(\nabla f\) is orthogonal to the tangent vector \(\frac {\diff x}{\diff t}\). Because this tangent
vector is arbitrary, \(\nabla f\) is orthogonal to the tangent space \(T_p M_{\mathrm {o}}^{n-1}\) at \(p\) and \(\mathrm {span}\left \{ \nabla f \right \}\) is the normal space \(N_p M_{\mathrm {o}}^{n-1}\), which is the
orthogonal complement of \(T_p M_{\mathrm {o}}^{n-1}\). Similarly, for the constraint function \(\varphi _i\), \(\mathrm {span} \left \{ \nabla \varphi _i \right \}\) is the normal space \(N_p M_{\mathrm {c}_i}^{n-1}\), which
is the orthogonal complement of \(T_p M_{\mathrm {c}_i}^{n-1}\). Then \(\mathrm {span} \left \{ \nabla \varphi _1,\cdots ,\nabla \varphi _m \right \}\) is the normal space \(N_p M_{\mathrm {c}}^{n-m}\) of \(M_{\mathrm {c}}^{n-m}\). This can be simply verified as
below.
</p><!-- l. 197 --><p class='indent'>   Let \(u=\sum _{i=1}^m \lambda _i \nabla \varphi _i\) be any vector in this normal space. For any vector \(v\) in the tangent space \(T_p M_{\mathrm {c}}^{n-m}\) of \(M_{\mathrm {c}}^{n-m}\), because \(v\) is orthogonal to any
\(\nabla \varphi _i\), we have \(\langle u,v \rangle = 0\), i.e. \(u\) is orthogonal to \(v\). Therefore, \(\mathrm {span} \left \{ \nabla \varphi _1,\cdots ,\nabla \varphi _m \right \}\) is a normal space.
</p><!-- l. 199 --><p class='indent'>   Now, let’s check the new objective function after applying the method of Lagrange multiplier, which is \begin{equation}  L(x^1,\cdots ,x^n,\lambda _1,\cdots ,\lambda _m) = f(x^1,\cdots ,x^n) + \sum _{i=1}^m \lambda _i \varphi _i(x^1,\cdots ,x^n).  \end{equation}<a id='x5-10009r5'></a> To
find critical points of \(L\), we need to enforce two types of conditions \begin{equation}  \frac {\partial L}{\partial x^{i}} = 0, \quad i=1,\cdots ,n,  \end{equation}<a id='x5-10010r6'></a> and \begin{equation}  \frac {\partial L}{\partial \lambda _j} = 0, \quad j=1,\cdots ,m.  \end{equation}<a id='x5-10011r7'></a> From the first type, we have \begin{equation}  \frac {\partial f}{\partial x^{i}} + \sum _{k=1}^m \lambda _k \frac {\partial \varphi _{k}}{\partial x^{i}} = 0, \quad i=1,\cdots ,n.  \end{equation}<a id='x5-10012r8'></a> This is
equivalent to \begin{equation}  df + \sum _{k=1}^m \lambda _k d\varphi _k = 0.  \end{equation}<a id='x5-10013r9'></a> Applying the inverse of the metric tensor \(g_{ij}\) to this equation, i.e. using the sharp operator \(\sharp \) to
transform the 1-forms \(df\) and \(d\varphi _k\) to tangent vectors, we obtain the equation for gradient vectors: \begin{equation}  \nabla f + \sum _{k=1}^m \lambda _k \nabla \varphi _k = 0,  \end{equation}<a id='x5-10014r10'></a> which means the
two level sets \(M_{\mathrm {o}}^{n-1}\) and \(M_{\mathrm {c}}^{n-m}\) have a same normal space.
</p><!-- l. 225 --><p class='indent'>   The second type of conditions \(\frac {\partial L}{\partial \lambda _{j}} = 0\) is simply enforcing the original constraint \(\varphi _j = 0\).
</p><!-- l. 227 --><p class='indent'>   <span class='p1xb-x-x-109'>In summary, the first condition in the Lagrange multiplier method is the normal space condition, while
</span><span class='p1xb-x-x-109'>the second is the constraint condition.</span>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2.2    </span> <a id='x5-110002.2'></a>Application of Lagrange multiplier method in PDEs</h3>
<!-- l. 230 --><p class='noindent'>Let \(X\) be a Hilbert space and \(X'\) be its dual space. \(\left \langle \cdot ,\cdot \right \rangle _X\) is the inner product in \(X\) and \(\left \langle \cdot ,\cdot \right \rangle \) is the duality pairing, which applies a
linear functional \(f\in X'\) to an element \(u\in X\), i.e. \(\left \langle f,u \right \rangle =\left \langle u,f \right \rangle =f(u)\). \(A: X \rightarrow X'\) is a bounded linear operator satisfying \begin{equation}  \norm {Av}_{X'}\leq c_2^A\norm {v}_X \quad \forall v \in X.  \end{equation}<a id='x5-11001r11'></a> We also assume \(A\) is self-adjoint in
the sense of normed space (see Section <span class='p1xb-x-x-109'>??</span>).
</p><!-- l. 236 --><p class='indent'>   For the operator equation \(Au=f\), where \(f\in X'\), we already know that it is equivalent to the variational equation \(\langle Au,v \rangle = \langle f,v \rangle \) for all \(v\in X\)
due to the boundedness of \(A\). If we further assume \(A\) is positive semi-definite, i.e. \begin{equation}  \langle Av,v \rangle \geq 0 \quad \forall v\in X,  \end{equation}<a id='x5-11002r12'></a> this variational equation is
equivalent to a minimization of a functional without constraint: \begin{equation}  u = \underset {v\in X}{\argmin }\; F(v) = \underset {v\in X}{\argmin }\; \frac {1}{2} \langle Av,v \rangle - \langle f,v \rangle .  \end{equation}<a id='x5-11003r13'></a> This can be proved by perturbing \(u\) with \(tw\), where \(w\in X\)
and \(t\) is a small scalar value. By letting \(\frac {\diff F(u+tw)}{\diff t} = 0\) at \(t=0\), we can obtain the variational formulation \(\langle Au,w \rangle = \langle f,w \rangle \) and also show that \(F(u)\) is a
minimum value.
</p>
                                                                                               
                                                                                               
   <div class='proof'><div class='newtheorem'>
<!-- l. 246 --><p class='noindent'><span class='head'>
<span class='p1xsc-x-x-109'>P<span class='small-caps'>roof</span></span> </span><a id='x5-11005'></a>\begin{equation}  \begin{aligned} F(u+tw) &amp;= \frac {1}{2} \langle A(u+tw),u+tw \rangle - \langle f,u+tw \rangle \\ &amp;= \frac {1}{2} \langle Au,u \rangle - \langle f,u \rangle + \frac {1}{2} \langle Au,tw \rangle + \frac {1}{2} \langle A(tw), u \rangle + \\ &amp;\quad \frac {1}{2} \langle A(tw),tw \rangle - \langle f,tw \rangle \end{aligned}  \end{equation}<a id='x5-11006r14'></a>
</p><!-- l. 257 --><p class='indent'>   Because \(A\) is self-adjoint, the fourth term above \(\langle A(tw),u \rangle = \langle tw,Au \rangle \) and we have \begin{equation}  \begin{aligned} F(u+tw) &amp;= F(u) + t\langle Au,w \rangle + \frac {1}{2} t^2 \langle Aw,w \rangle - t\langle f,w \rangle \\ &amp;= F(u) + t \left ( \langle Au,w \rangle - \langle f,w \rangle \right ) + \frac {1}{2} t^2 \langle Aw,w \rangle \end{aligned}.  \end{equation}<a id='x5-11007r15'></a> Let the derivative of \(F(u+tw)\) at \(t=0\) be 0: \begin{equation}  \frac {\diff F(u+tw)}{\diff t} \Big \vert _{t=0} = \langle Au,w \rangle - \langle f,w \rangle = 0,  \end{equation}<a id='x5-11008r16'></a> which is the
variational equation.
</p><!-- l. 272 --><p class='indent'>   We can also directly compute the variation \(\delta F(v)\) of the functional \(F(v)\) to derive the variational equation. The variation
\(\delta F(v)\) is the linear part of the changes in \(F(v)\) when there is a perturbation \(\delta v\) added to \(v\), i.e. \begin{equation}  F(v+\delta v) - F(v) = \delta F(v) \delta v + O(\delta v^2) + \cdots ,  \end{equation}<a id='x5-11009r17'></a> where \(O(\delta v^2)\) and more subsequent
terms are the high order changes with respect to \(\delta v\). <span class='p1xb-x-x-109'>The variation operator </span>\(\delta \) <span class='p1xb-x-x-109'>commutes with differential
</span><span class='p1xb-x-x-109'>and integral operators. It also satisfies the chain rule for the normal differential operator. </span>Then
we have \begin{equation}  \begin{aligned} \delta F(v) &amp;= \frac {1}{2} \langle A\delta v,v \rangle + \frac {1}{2} \langle Av,\delta v \rangle - \langle f,\delta v \rangle \\ &amp;= \langle Av,\delta v \rangle - \langle f,\delta v \rangle \end{aligned}.  \end{equation}<a id='x5-11010r18'></a> Let \(\delta F(v) = 0\), we obtain the variational formulation \(\langle Av, \delta v \rangle = \langle f,\delta v \rangle \). \(\delta v\) is arbitrary and can be replaced with any
\(w\in X\).
</p><!-- l. 286 --><p class='indent'>   Next, we will show that \(F(v)\) achieves the minimum value when \(v\) is the solution \(u\) of the variational equation. In
the above, we already have \begin{equation}  F(u+tw) = F(u) + t \left ( \langle Au,w \rangle - \langle f,w \rangle \right ) + \frac {1}{2} t^2 \langle Aw,w \rangle .  \end{equation}<a id='x5-11011r19'></a> Because \(u\) is the solution of the variational equation, the second term \(t \left ( \langle Au,w \rangle - \langle f,w \rangle \right )\) is zero.
Meanwhile, considering the assumption that \(A\) is positive semi-definite, we have \(\frac {1}{2} t^2 \langle Aw,w \rangle \geq 0\) and \(F(u) \leq F(u+tw)\), which means \(u\) is a local
minima of the functional \(F(v)\).
</p>
   </div>
<!-- l. 291 --><p class='indent'>   </p></div>
<!-- l. 293 --><p class='indent'>   If there is a constraint in the form of an operator equation \(Bu=g\), where \(B: X \rightarrow \Pi '\) is a bounded linear operator and \(g\in \Pi '\), \(\Pi \) is a
Banach space and \(\Pi '\) is its dual space, using the Lagrange multiplier method, we can obtain a new functional \begin{equation}  \begin{aligned} L(v,p) &amp;:= \frac {1}{2} \langle Av,v \rangle - \langle f,v \rangle + \langle Bv-g,p \rangle \\ &amp;= \frac {1}{2} \langle Av,v \rangle - \langle f,v \rangle + \langle Bv,p \rangle - \langle g,p \rangle \end{aligned},  \end{equation}<a id='x5-11012r20'></a>
where \(p\in \Pi \) is the Lagrange multiplier. <span class='p1xb-x-x-109'>Note that a Lagrange multiplier introduced into a PDE for the operator
</span><span class='p1xb-x-x-109'>equation constraint is not a scalar value anymore, but a function in the test function space. The
</span><span class='p1xb-x-x-109'>constraint </span>\(Bv=g\) <span class='p1xb-x-x-109'>is also weakly enforced, i.e. </span>\(Bv-g\) <span class='p1xb-x-x-109'>is multiplied with </span>\(p\) <span class='p1xb-x-x-109'>and then integrated on the whole
</span><span class='p1xb-x-x-109'>domain.</span>
</p><!-- l. 304 --><p class='indent'>   In this new functional \(L(v,p)\), there is only one variable and one Lagrange multiplier, both of which are functions.
To find the critical points of \(L(v,p)\), we first perturb \(v\) with \(tw\) where \(w\in X\), then \begin{equation}  \begin{aligned} L(v+tw,p) &amp;= \frac {1}{2} \langle Av,v \rangle - \langle f,v \rangle + t \left ( \langle Av,w \rangle - \langle f,w \rangle \right ) + \\ &amp;\quad \frac {1}{2} t^2\langle Aw,w \rangle + \langle Bv,p \rangle + \langle B(tw),p \rangle - \langle g,p \rangle \end{aligned}.  \end{equation}<a id='x5-11013r21'></a> Let \begin{equation}  \frac {\diff L(v+tw,p)}{\diff t} \Big \vert _{t=0} = 0,  \end{equation}<a id='x5-11014r22'></a> we have \begin{equation}  \langle Av,w \rangle + \langle Bw,p \rangle = \langle f,w \rangle .  \end{equation}<a id='x5-11015r23'></a>
</p><!-- l. 322 --><p class='indent'>   Then we perturb \(p\) with \(tq\) where \(q\in \Pi \), then \begin{equation}  L(v,p+tq) = \frac {1}{2} \langle Av,v \rangle - \langle f,v \rangle + \langle Bv,p \rangle + \langle Bv,tq \rangle - \langle g,p \rangle - \langle g,tq \rangle .  \end{equation}<a id='x5-11016r24'></a> Let \begin{equation}  \frac {\diff L(v,p+tq)}{\diff t} \Big \vert _{t=0} = 0,  \end{equation}<a id='x5-11017r25'></a> we have \begin{equation}  \langle Bv,q \rangle = \langle g,q \rangle .  \end{equation}<a id='x5-11018r26'></a> Combine the above two equations and replace \(v\) with \(u\), \(w\)
with \(v\) symbolically, the familiar mixed variational formulation can be obtained: \begin{equation}  \begin{aligned} \langle Au,v \rangle + \langle Bv,p \rangle &amp;= \langle f,v \rangle \\ \langle Bu,q \rangle &amp;= \langle g,q \rangle \end{aligned},  \end{equation}<a id='x5-11019r27'></a> where \((u,p)\in X\times \Pi \) is the solution to be
found and \((v,q)\in X\times \Pi \) is the test function. It can be proved that the critical point of the functional \(L(v,p)\) found by the Lagrange
multiplier method is neither a maximum or minimum, but a saddle point (see Figure <a href='#x5-11020r1'>2.1<!-- tex4ht:ref: fig:saddle-point-of-functional  --></a>). Hence, the mixed
variational formulation is also a saddle point problem. When it is discretized into a block matrix system, the
matrix is not symmetric positive definite (SPD) or Hermitian positive definite (HPD) anymore. Therefore,
it should be solved with an iterative solver like BiCGStab, but not the conjugate gradient (CG)
method.
</p>
   <figure class='figure'> 

                                                                                               
                                                                                               
<a id='x5-11020r1'></a>
                                                                                               
                                                                                               
<!-- l. 345 --><p class='noindent'><img alt='PIC'  width="90%" src='figures/2024-06-07-18-41-lagrangian-multiplier-for-constraint-pde.png'  />
</p>
<figcaption class='caption'><span class='id'>Figure 2.1: </span><span class='content'>Saddle point of the functional \(L(v,p)\).</span></figcaption><!-- tex4ht:label?: x5-11020r1  -->
                                                                                               
                                                                                               
   </figure>
   <h3 class='sectionHead'><span class='titlemark'>2.3    </span> <a id='x5-120002.3'></a>Summary</h3>
     <ul class='itemize1'>
     <li class='itemize'>
     <!-- l. 351 --><p class='noindent'>The essence of the general Lagrange multiplier method is looking for the common tangent or normal
     space  between  two  high  dimensional  submanifolds  or  level  sets  associated  with  the  objective
     function and one or multiple constraint functions. This method can be used to find critical points
     of the objective function. Whether they are minimum, maximum or saddle points needs further
     inspection or proof.
     </p></li>
     <li class='itemize'>
     <!-- l. 352 --><p class='noindent'>The critical points can be found by equating the partial derivatives of the modified objective function
     to zeros. The partial derivatives with respect to independent variables enforce the common normal
     space  condition,  while  the  partial  derivatives  with  respect  to  Lagrange  multipliers  enforce  the
     constraints.
     </p></li>
     <li class='itemize'>
     <!-- l. 353 --><p class='noindent'>In a PDE, a Lagrange multiplier introduced for a constraint in the form of an operator equation is
     a <span class='p1xb-x-x-109'>function </span>instead of a <span class='p1xb-x-x-109'>scalar </span>value. When it is appended to the new objective function without
     constraints, it should be multiplied with the constraint operator equation (all terms moving to the
     left hand side, i.e. \(Bu-g=0\)) and then integrated on the whole domain, e.g. \(\langle Bu-g,p \rangle \). Therefore, the constraint is
     weakly enforced and the Lagrange multiplier can be considered as a test function.
     </p><!-- l. 355 --><p class='noindent'>However, it is also possible that the constraint is only a scalar valued equation. For example, in the
     boundary integral equation (BIE) for the Laplace problem with the Neumann boundary condition, because
     the kernel of the hypersingular operator is nontrivial, the solution should be sought in a subspace such as \(H_{\ast }^{1/2}(\Gamma )\)
     instead of the whole space \(H^{1/2}(\Gamma )\). Then a scalar valued constraint \(\langle \gamma _0^{\mathrm {int}}u, w_{\mathrm {eq}} \rangle _{\Gamma } = 0\) is needed to confine the solution within this
     subspace, where \(w_{\mathrm {eq}}\) is the natural density. The Lagrange multiplier for introducing this constraint
     into the Lagrange functinal is a scalar value as usual. The derived saddle point problem is
     \begin{equation}  \begin{aligned} \langle D \gamma _0^{\mathrm {int}}u,v \rangle _{\Gamma } + \lambda \langle v, w_{\mathrm {eq}} \rangle _{\Gamma } &amp;= \langle (\frac {1}{2} I - K')g, v \rangle _{\Gamma } \\ \langle \gamma _0^{\mathrm {int}}u,w_{\mathrm {eq}} \rangle _{\Gamma } &amp;= 0 \end{aligned}.  \end{equation}<a id='x5-12001r28'></a>
     </p></li>
     <li class='itemize'>
     <!-- l. 363 --><p class='noindent'>Due to the boundedness, self-adjointness and positive semi-definiteness of the partial differential operator \(A\)
     as well as the boundedness of the constraint operator \(B\), the critical point of the functional \(L(v,p)\) is a saddle
     point.</p></li></ul>
<!-- l. 365 --><div class='crosslinks'><p class='noindent'>[<a href='hierbem-theorych2.html'>front</a>] [<a href='hierbem-theorypa2.html#hierbem-theorych2.html'>up</a>] </p></div>
<!-- l. 365 --><p class='indent'>   <a id='tailhierbem-theorych2.html'></a>  </p> 
</body> 
</html>
